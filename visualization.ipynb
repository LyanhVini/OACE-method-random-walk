{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics_per_iteration.json', 'r') as f:\n",
    "    metrics_per_iteration = json.load(f)\n",
    "    \n",
    "with open('oace_metrics_per_iteration.json', 'r') as f:\n",
    "    oace_metrics_per_iteration = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_assertiveness_metrics(data):\n",
    "    # Inicializa listas para armazenar as iterações e os valores das métricas\n",
    "    iterations = []\n",
    "    precision_values = []\n",
    "    accuracy_values = []\n",
    "    recall_values = []\n",
    "    \n",
    "    # Extrai os dados do dicionário\n",
    "    for key, value in data.items():\n",
    "        iterations.append(int(key))\n",
    "        precision_values.append(value['assertividade']['precision'])\n",
    "        accuracy_values.append(value['assertividade']['accuracy'])\n",
    "        recall_values.append(value['assertividade']['recall'])\n",
    "    \n",
    "    # Cria o gráfico de linha interativo com Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Adiciona as linhas das métricas precision, accuracy e recall\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=precision_values, mode='lines+markers', name='Precision'))\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=accuracy_values, mode='lines+markers', name='Accuracy'))\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=recall_values, mode='lines+markers', name='Recall'))\n",
    "    \n",
    "    # Configurações do layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title='Assertiveness Metrics Over Iterations',\n",
    "        xaxis_title='Iteration',\n",
    "        yaxis_title='Metric Value',\n",
    "        legend_title='Metrics',\n",
    "        template='plotly',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Mostra o gráfico\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oace_metrics(data):\n",
    "    # Inicializa listas para armazenar as iterações e os valores das métricas\n",
    "    iterations = []\n",
    "    A_values = []\n",
    "    C_values = []\n",
    "    Score_values = []\n",
    "    \n",
    "    # Extrai os dados do dicionário\n",
    "    for key, value in data.items():\n",
    "        iterations.append(int(key))\n",
    "        A_values.append(value['A'])\n",
    "        C_values.append(value['C'])\n",
    "        Score_values.append(value['Score'])\n",
    "    \n",
    "    # Cria o gráfico de linha interativo com Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Adiciona as linhas das métricas A, C e Score\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=A_values, mode='lines+markers', name='A'))\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=C_values, mode='lines+markers', name='C'))\n",
    "    fig.add_trace(go.Scatter(x=iterations, y=Score_values, mode='lines+markers', name='Score'))\n",
    "    \n",
    "    # Configurações do layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title='OACE Metrics Over Iterations',\n",
    "        xaxis_title='Iteration',\n",
    "        yaxis_title='Metric Value',\n",
    "        legend_title='Metrics',\n",
    "        template='plotly',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Mostra o gráfico\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_assertiveness_metrics(metrics_per_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_oace_metrics(oace_metrics_per_iteration)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
